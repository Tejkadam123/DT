{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51087b1c",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77852260",
   "metadata": {},
   "outputs": [],
   "source": [
    "It is a supervised ml algorithm which can be used for classification as well as regression. \n",
    "Mainly it used for classification\n",
    "\n",
    "Attribute Seelction Measure [ASM]: \n",
    "    1. Entropy [Information Gain]\n",
    "    2. Gini index \n",
    "    \n",
    "    Entropy : Measure of impurity\n",
    "        \n",
    "IG >> Max >> 0 to 1\n",
    "GI >> Min >> 0 to 0.5\n",
    "\n",
    "Technical Terms for Decision Tree \n",
    "\n",
    "Root Node >> Initial Node [Decision Node]\n",
    "Branch Node >> Decision Node\n",
    "Leaf Node >> Terminal Node / Pure Node / Final Node [Prediction]\n",
    "\n",
    "\n",
    "\n",
    "ID3 >> Iterative Dichotomiser 3 >> Entropy\n",
    "CART >> Classification and Regression Tree >> gini\n",
    "C4.5 >> Successor ID3 >> Advanced version of ID3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression \n",
    "\n",
    "ASM: \n",
    "    1. Sequared Value  \"mse\" >> \"SE\"\n",
    "    2. Absolute Values \"mae\" >> \"AE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790e898",
   "metadata": {},
   "source": [
    "### Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd99638",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. criterion \n",
    "2. max_depth \n",
    "3. min_samples_split\n",
    "4. min_samples_leaf\n",
    "5. max_features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088437c",
   "metadata": {},
   "source": [
    "## Advatnages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2db786",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Used for Regression and classifiction \n",
    "2. Easy to understand and iterrpret\n",
    "3. Its Non- Parametric (No Assumptions of distribution of data )\n",
    "4. not Sensitive to Outliers \n",
    "5. Not Requires scaling \n",
    "6. It Can handle numerical data as well as categorical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d30ac8",
   "metadata": {},
   "source": [
    "## Disadvantges of DT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Overfitting :\n",
    "    ## How to prevent \n",
    "    1. Hyperparameter tuing \n",
    "    2. Pruning\n",
    "    3. USE ENSEMBEL Methods:\n",
    "        1. Bagging: (Parrallel)\n",
    "            RAndom Forest Algorithm \n",
    "        2. Boosting: (Sequentail Technique)\n",
    "            AdaBoosting \n",
    "            GradBoosting \n",
    "            XGBoost\n",
    "2. Decision tree can be unstable (small changes in dataset can chnage whole decision tree structure)\n",
    "3. DT calulation sometimes more complex than other algorithms. \n",
    "4. DT often require more time to train model (realtively expensive to train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
